{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands of demonstrators have marched throug...</td>\n",
       "      <td>['NNS', 'IN', 'NNS', 'VBP', 'VBN', 'IN', 'NNP'...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 2</td>\n",
       "      <td>Families of soldiers killed in the conflict jo...</td>\n",
       "      <td>['NNS', 'IN', 'NNS', 'VBN', 'IN', 'DT', 'NN', ...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 3</td>\n",
       "      <td>They marched from the Houses of Parliament to ...</td>\n",
       "      <td>['PRP', 'VBD', 'IN', 'DT', 'NNS', 'IN', 'NN', ...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 4</td>\n",
       "      <td>Police put the number of marchers at 10,000 wh...</td>\n",
       "      <td>['NNS', 'VBD', 'DT', 'NN', 'IN', 'NNS', 'IN', ...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 5</td>\n",
       "      <td>The protest comes on the eve of the annual con...</td>\n",
       "      <td>['DT', 'NN', 'VBZ', 'IN', 'DT', 'NN', 'IN', 'D...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47954</th>\n",
       "      <td>Sentence: 47955</td>\n",
       "      <td>Indian border security forces are accusing the...</td>\n",
       "      <td>['JJ', 'NN', 'NN', 'NNS', 'VBP', 'VBG', 'PRP$'...</td>\n",
       "      <td>['B-gpe', 'O', 'O', 'O', 'O', 'O', 'O', 'B-gpe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47955</th>\n",
       "      <td>Sentence: 47956</td>\n",
       "      <td>Indian officials said no one was injured in Sa...</td>\n",
       "      <td>['JJ', 'NNS', 'VBD', 'DT', 'NN', 'VBD', 'VBN',...</td>\n",
       "      <td>['B-gpe', 'O', 'O', 'O', 'O', 'O', 'O', 'O', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47956</th>\n",
       "      <td>Sentence: 47957</td>\n",
       "      <td>Two more landed in fields belonging to a nearb...</td>\n",
       "      <td>['CD', 'JJR', 'VBD', 'IN', 'NNS', 'VBG', 'TO',...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47957</th>\n",
       "      <td>Sentence: 47958</td>\n",
       "      <td>They say not all of the rockets exploded upon ...</td>\n",
       "      <td>['PRP', 'VBP', 'RB', 'DT', 'IN', 'DT', 'NNS', ...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47958</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>Indian forces said they responded to the attack</td>\n",
       "      <td>['JJ', 'NNS', 'VBD', 'PRP', 'VBD', 'TO', 'DT',...</td>\n",
       "      <td>['B-gpe', 'O', 'O', 'O', 'O', 'O', 'O', 'O']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47959 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Sentence #                                           Sentence  \\\n",
       "0          Sentence: 1  Thousands of demonstrators have marched throug...   \n",
       "1          Sentence: 2  Families of soldiers killed in the conflict jo...   \n",
       "2          Sentence: 3  They marched from the Houses of Parliament to ...   \n",
       "3          Sentence: 4  Police put the number of marchers at 10,000 wh...   \n",
       "4          Sentence: 5  The protest comes on the eve of the annual con...   \n",
       "...                ...                                                ...   \n",
       "47954  Sentence: 47955  Indian border security forces are accusing the...   \n",
       "47955  Sentence: 47956  Indian officials said no one was injured in Sa...   \n",
       "47956  Sentence: 47957  Two more landed in fields belonging to a nearb...   \n",
       "47957  Sentence: 47958  They say not all of the rockets exploded upon ...   \n",
       "47958  Sentence: 47959    Indian forces said they responded to the attack   \n",
       "\n",
       "                                                     POS  \\\n",
       "0      ['NNS', 'IN', 'NNS', 'VBP', 'VBN', 'IN', 'NNP'...   \n",
       "1      ['NNS', 'IN', 'NNS', 'VBN', 'IN', 'DT', 'NN', ...   \n",
       "2      ['PRP', 'VBD', 'IN', 'DT', 'NNS', 'IN', 'NN', ...   \n",
       "3      ['NNS', 'VBD', 'DT', 'NN', 'IN', 'NNS', 'IN', ...   \n",
       "4      ['DT', 'NN', 'VBZ', 'IN', 'DT', 'NN', 'IN', 'D...   \n",
       "...                                                  ...   \n",
       "47954  ['JJ', 'NN', 'NN', 'NNS', 'VBP', 'VBG', 'PRP$'...   \n",
       "47955  ['JJ', 'NNS', 'VBD', 'DT', 'NN', 'VBD', 'VBN',...   \n",
       "47956  ['CD', 'JJR', 'VBD', 'IN', 'NNS', 'VBG', 'TO',...   \n",
       "47957  ['PRP', 'VBP', 'RB', 'DT', 'IN', 'DT', 'NNS', ...   \n",
       "47958  ['JJ', 'NNS', 'VBD', 'PRP', 'VBD', 'TO', 'DT',...   \n",
       "\n",
       "                                                     Tag  \n",
       "0      ['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', '...  \n",
       "1      ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n",
       "2      ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n",
       "3      ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n",
       "4      ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n",
       "...                                                  ...  \n",
       "47954  ['B-gpe', 'O', 'O', 'O', 'O', 'O', 'O', 'B-gpe...  \n",
       "47955  ['B-gpe', 'O', 'O', 'O', 'O', 'O', 'O', 'O', '...  \n",
       "47956  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n",
       "47957  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n",
       "47958       ['B-gpe', 'O', 'O', 'O', 'O', 'O', 'O', 'O']  \n",
       "\n",
       "[47959 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('ner.csv', encoding='ISO-8859-1')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 47959 entries, 0 to 47958\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Sentence #  47959 non-null  object\n",
      " 1   Sentence    47959 non-null  object\n",
      " 2   POS         47959 non-null  object\n",
      " 3   Tag         47959 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence #    0\n",
       "Sentence      0\n",
       "POS           0\n",
       "Tag           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = df['Sentence'].to_numpy()\n",
    "tags = df['Tag'].apply(lambda x: x[1:-1].replace(\"'\", \"\").replace(\",\", \"\")).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country .',\n",
       "       'Families of soldiers killed in the conflict joined the protesters who carried banners with such slogans as \" Bush Number One Terrorist \" and \" Stop the Bombings . \"',\n",
       "       'They marched from the Houses of Parliament to a rally in Hyde Park .',\n",
       "       ..., 'Two more landed in fields belonging to a nearby village .',\n",
       "       'They say not all of the rockets exploded upon impact .',\n",
       "       'Indian forces said they responded to the attack'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['O O O O O O B-geo O O O O O B-geo O O O O O B-gpe O O O O O',\n",
       "       'O O O O O O O O O O O O O O O O O O B-per O O O O O O O O O O O',\n",
       "       'O O O O O O O O O O O B-geo I-geo O', ...,\n",
       "       'O O O O O O O O O O O', 'O O O O O O O O O O O',\n",
       "       'B-gpe O O O O O O O'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_tmp, y_train, y_tmp = train_test_split(\n",
    "    sentences, tags, test_size=1000, random_state=101)\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_tmp, y_tmp, test_size=0.5, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training samples: 46959\n",
      "Total validation samples: 500\n",
      "Total testing samples: 500\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total training samples: {len(X_train)}\")\n",
    "print(f\"Total validation samples: {len(X_val)}\")\n",
    "print(f\"Total testing samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_vectorizer(sentences):\n",
    "    sentence_vectorizer = layers.TextVectorization(standardize=None)\n",
    "    sentence_vectorizer.adapt(sentences)\n",
    "    vocab = sentence_vectorizer.get_vocabulary()\n",
    "\n",
    "    return sentence_vectorizer, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_vectorizer, vocab = get_sentence_vectorizer(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words in the training vocab: 34894\n",
      "\n",
      "Sentence: Nigeria 's parliament is debating a constitutional amendment proposed by supporters of Mr. Obasanjo that would permit presidents three terms in office instead of two .\n",
      "\n",
      "Sentence vectorized: [  723    11   273    14 10143     8  1177  3763   944    23   761     5\n",
      "    34  3601    16    93  4461  2413    94  1892     6   425  1853     5\n",
      "    44     3]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of unique words in the training vocab: {len(vocab)}\\n\")\n",
    "print(f\"Sentence: {X_train[0]}\\n\")\n",
    "print(f\"Sentence vectorized: {sentence_vectorizer(X_train[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Nigeria 's parliament is debating a constitutional amendment proposed by supporters of Mr. Obasanjo that would permit presidents three terms in office instead of two .\n",
      "Labels: B-geo O O O O O O O O O O O B-per B-org O O O O O O O O O O O O\n"
     ]
    }
   ],
   "source": [
    "print(f\"Sentence: {X_train[0]}\")\n",
    "print(f\"Labels: {y_train[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tags(labels):\n",
    "    tags = set()\n",
    "    for l in labels:\n",
    "        for tag in l.split(' '):\n",
    "            tags.add(tag)\n",
    "\n",
    "    return list(sorted(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-art', 'B-eve', 'B-geo', 'B-gpe', 'B-nat', 'B-org', 'B-per', 'B-tim', 'I-art', 'I-eve', 'I-geo', 'I-gpe', 'I-nat', 'I-org', 'I-per', 'I-tim', 'O']\n"
     ]
    }
   ],
   "source": [
    "tags = get_tags(y_train)\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_vectorizer(lables, tags):\n",
    "    label_ids = []\n",
    "    for l in lables:\n",
    "        tags_ids = [tags.index(tag) for tag in l.split(' ')]\n",
    "        label_ids.append(tags_ids)\n",
    "\n",
    "    return tf.keras.preprocessing.sequence.pad_sequences(label_ids, padding='post', value=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  6,  5, 16, 16,\n",
       "        16, 16, 16, 16, 16, 16, 16, 16, 16, 16],\n",
       "       [16, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_vectorizer([y_train[0], 'O'], tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(sentences, labels, sentence_vectorizer, label_vectorizer, tags):\n",
    "    sentences_ids = sentence_vectorizer(sentences)\n",
    "    label_ids = label_vectorizer(labels, tags)\n",
    "    ds = tf.data.Dataset.from_tensor_slices((sentences_ids, label_ids))\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = generate_dataset(X_train, y_train, sentence_vectorizer, label_vectorizer, tags)\n",
    "ds_val = generate_dataset(X_val, y_val, sentence_vectorizer, label_vectorizer, tags)\n",
    "ds_test = generate_dataset(X_test, y_test, sentence_vectorizer, label_vectorizer, tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: [  723    11   273    14 10143     8  1177  3763   944    23   761     5\n",
      "    34  3601    16    93  4461  2413    94  1892     6   425  1853     5\n",
      "    44     3     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0]\n",
      "Y: [ 2 16 16 16 16 16 16 16 16 16 16 16  6  5 16 16 16 16 16 16 16 16 16 16\n",
      " 16 16 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "for x, y in ds_train.take(1):\n",
    "    print(f\"X: {x}\")\n",
    "    print(f\"Y: {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NER(vocab_size, emb_dim, tags_size):\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    # vocab_size +1 -> Why +1? the padding token '0'\n",
    "    # why mask_zero? The value 0 should be reserved as the mask value, as it will be ignored in training.\n",
    "    model.add(layers.Embedding(input_dim=vocab_size+1, output_dim=emb_dim, mask_zero=True))\n",
    "    model.add(layers.LSTM(units=emb_dim, return_sequences=True))\n",
    "    model.add(layers.Dense(units=tags_size, activation=tf.nn.log_softmax))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_loss(y_true, y_pred):\n",
    "   loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, ignore_class=-1)\n",
    "   loss = loss_fn(y_true, y_pred)\n",
    "   return  loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_accuracy(y_true, y_pred):\n",
    "   \n",
    "\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "\n",
    "    mask = tf.not_equal(y_true, -1)\n",
    "    mask = tf.cast(mask, tf.float32)\n",
    "\n",
    "    y_pred_class = tf.math.argmax(y_pred, axis=-1)\n",
    "    y_pred_class = tf.cast(y_pred_class, tf.float32)\n",
    "\n",
    "    matches_true_pred  = tf.equal(y_true, y_pred_class)\n",
    "    matches_true_pred = tf.cast(matches_true_pred , tf.float32)\n",
    "\n",
    "    matches_true_pred *= mask\n",
    "\n",
    "    masked_acc = tf.reduce_sum(matches_true_pred) / tf.reduce_sum(mask)\n",
    "\n",
    "    return masked_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NER(len(vocab), 128, len(tags))\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "    loss=masked_loss,\n",
    "    metrics=[masked_accuracy]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m734/734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 108ms/step - loss: 0.3117 - masked_accuracy: 0.9229 - val_loss: 0.1099 - val_masked_accuracy: 0.9656\n",
      "Epoch 2/2\n",
      "\u001b[1m734/734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 103ms/step - loss: 0.0984 - masked_accuracy: 0.9682 - val_loss: 0.1105 - val_masked_accuracy: 0.9651\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "history = model.fit(\n",
    "    ds_train.batch(BATCH_SIZE),\n",
    "    validation_data=ds_val.batch(BATCH_SIZE),\n",
    "    shuffle=True,\n",
    "    epochs=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('NER.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('NER.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n"
     ]
    }
   ],
   "source": [
    "test_sentences_ids = sentence_vectorizer(X_test)\n",
    "y_true = label_vectorizer(y_test, tags)\n",
    "\n",
    "y_pred = model.predict(test_sentences_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model's accuracy in test set is: 0.9613\n"
     ]
    }
   ],
   "source": [
    "print(f\"The model's accuracy in test set is: {masked_accuracy(y_true, y_pred).numpy():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sentence, model, sentence_vectorizer, tags):\n",
    "\n",
    "    sentence_ids = sentence_vectorizer(sentence)\n",
    "    sentence_ids = tf.expand_dims(sentence_ids, axis=0)\n",
    "\n",
    "    output = model.predict(sentence_ids)\n",
    "\n",
    "    outputs = np.argmax(output, axis=-1)\n",
    "    outputs = outputs[0]\n",
    "\n",
    "    pred = [tags[tag_idx] for tag_idx in outputs]\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\n",
      "Sentence: Mustafa is going to Gaza (Palestine) next Ramadan with Mohamed to kill the Israel Army\n",
      "\n",
      "NER Tags: B-per O O O B-geo I-geo O B-tim O B-per O O O B-geo I-org\n",
      "\n",
      "╭─────────────┬───────╮\n",
      "│ Word        │ Tag   │\n",
      "├─────────────┼───────┤\n",
      "│ Mustafa     │ B-per │\n",
      "│ is          │ O     │\n",
      "│ going       │ O     │\n",
      "│ to          │ O     │\n",
      "│ Gaza        │ B-geo │\n",
      "│ (Palestine) │ I-geo │\n",
      "│ next        │ O     │\n",
      "│ Ramadan     │ B-tim │\n",
      "│ with        │ O     │\n",
      "│ Mohamed     │ B-per │\n",
      "│ to          │ O     │\n",
      "│ kill        │ O     │\n",
      "│ the         │ O     │\n",
      "│ Israel      │ B-geo │\n",
      "│ Army        │ I-org │\n",
      "╰─────────────┴───────╯\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Mustafa is going to Gaza (Palestine) next Ramadan with Mohamed to kill the Israel Army\"\n",
    "\n",
    "ner = predict(sentence, model, sentence_vectorizer, tags)\n",
    "\n",
    "table = [[word, tag] for word, tag in zip(sentence.split(' '), ner)]\n",
    "\n",
    "print(f\"\\nSentence: {sentence}\\n\")\n",
    "print(f\"NER Tags: {' '.join(ner)}\\n\")\n",
    "print(tabulate.tabulate(table, headers=['Word', 'Tag'], tablefmt='rounded_outline'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
